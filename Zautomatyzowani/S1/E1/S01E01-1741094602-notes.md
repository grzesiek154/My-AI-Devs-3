# 1. Wprowadzenie do możliwości AI i LLM

- Umiejętności takie jak czytanie, pisanie, słuchanie, mówienie, rysowanie czy rozumowanie są obecnie dostępne dla komputerów dzięki AI.
- AI może wykonywać zadania na podstawie tekstu lub nagrań audio.
- Możliwość integracji AI z różnymi narzędziami i automatyzacjami.
- Pamięć długoterminowa nie jest domyślnie dostępna w aplikacji Alice, ale można ją zbudować samodzielnie.
- AI może generować obrazy na podstawie opisów tekstowych.

# 2. Co znajduje się „po drugiej stronie ChatGPT”?

- ChatGPT to interfejs do dużego modelu językowego (LLM).
- Wymiana wiadomości odbywa się przez serwery OpenAI, gdzie każda wiadomość jest analizowana przez LLM.
- Możliwa jest bezpośrednia interakcja z LLM przez API, co pozwala na automatyzacje bez udziału człowieka.
- Automatyzacje mogą współpracować ze sobą, przekraczając możliwości pojedynczego LLM.

# 3. Czym jest Generatywna Sztuczna Inteligencja?

- Generatywna AI to obszar AI zdolny do generowania treści (tekst, obrazy, dźwięk).
- Programy komputerowe opierają się na zestawie zasad, ale procesy kreatywne są trudne do opisania w kodzie.
- AI modeluje rzeczywistość na podstawie uproszczeń, podobnie jak mapy.
- Sieci neuronowe są trenowane na dużych zbiorach danych, by realizować określone zadania.

# 4. Wnioski z teorii działania dużych modeli językowych

- ChatGPT to narzędzie wizualne do kontaktu z LLM.
- Możliwa jest interakcja z LLM przez API i narzędzia no-code.
- LLM opierają się na sieciach neuronowych, których działania nie rozumiemy w pełni.
- LLM generują treść przez przewidywanie kolejnych fragmentów tekstu.
- Modele mają zamknięty czas treningu i nie uczą się nowych rzeczy po jego zakończeniu.
- Możliwe jest połączenie LLM z zewnętrznymi źródłami danych.

# 5. Praktyczne możliwości oraz ograniczenia LLM

- LLM mają limit długości przetwarzanej treści (token window).
- Ograniczona zdolność do utrzymywania uwagi – niektóre fragmenty mogą być pominięte.
- Odpowiedzi mogą zawierać błędy, nawet jeśli brzmią wiarygodnie.
- Generowane treści to tokeny, a limit obejmuje zarówno wejście, jak i wyjście.
- Nie mamy pełnej kontroli nad zachowaniem LLM, ale możemy je sterować przez instrukcje.

# 6. Niedeterministyczna natura

- Odpowiedzi LLM są niedeterministyczne – ten sam input może dać różne outputy.
- Brak możliwości pełnej kontroli nad zachowaniem modelu.
- Można zmniejszać ryzyko niepożądanych odpowiedzi przez odpowiednie instrukcje.

# 7. Ograniczenia bazowej wiedzy

- LLM nie mają nieograniczonej wiedzy i mogą nie znać aktualnych informacji.
- Brak danych może prowadzić do błędnych odpowiedzi.
- Możliwe jest połączenie LLM z własnymi źródłami wiedzy lub Internetem, ale nie eliminuje to całkowicie problemu.

# 8. Wpływ na zachowanie

- Zachowanie LLM można kształtować przez instrukcje i formatowanie inputu.
- Cała konwersacja wpływa na jakość odpowiedzi.
- Precyzyjne formatowanie odpowiedzi jest kluczowe w automatyzacjach.

# 9. Ograniczona inteligencja

- LLM uczą się przez odkrywanie schematów w danych treningowych.
- Modele mogą mieć trudności z rozumieniem relacji i złożonych zależności.
- Poprowadzenie modelu przez proces myślowy może poprawić jakość odpowiedzi.

# 10. Skąd czerpać wiedzę na temat dużych modeli językowych?

- Wiedza pochodzi z praktyki, teorii od twórców LLM oraz publikacji naukowych.
- Rekomendowane źródła to dokumentacje, przewodniki, społeczności i profile ekspertów.

# 11. Praca wspólnie ze Sztuczną Inteligencją

- Współpraca z AI polega na optymalizacji procesów, a nie pełnym zastąpieniu człowieka.
- Ważne jest dostarczanie kontekstu i precyzyjnych instrukcji.
- Często celem jest częściowy rezultat, który człowiek może dalej rozwijać.
- Najlepsze efekty daje współpraca, gdzie AI uzupełnia kompetencje człowieka.

# 12. Zadanie na dziś

- Zadanie polega na opisaniu, jak Generatywna Sztuczna Inteligencja pomaga w pracy lub jak mogłaby pomóc.
- Należy uwzględnić opis aktywności, rolę AI, potencjalne problemy i największą wartość.
- Ważne jest zwrócenie uwagi na długoterminowy wpływ AI.

---

# External Resources

- [Prompt Engineering od OpenAI](https://platform.openai.com/docs/guides/prompt-engineering)
- [Prompting Guide](https://www.promptingguide.ai/)
- [OpenAI CookBook](https://cookbook.openai.com/)
- [OpenAI Research](https://openai.com/research)
- [Anthropic Research](https://www.anthropic.com/research)
- [OpenAI Community](https://community.openai.com/)
- [Społeczność AI Explained](https://www.youtube.com/@aiexplained-official/videos)
- [Andrej Karpathy](https://twitter.com/karpathy)
- [Geoffrey Hinton](https://twitter.com/geoffreyhinton)
- [Yann Lecun](https://twitter.com/ylecun)
- [Two Minute Papers](https://www.youtube.com/@TwoMinutePapers)
- [CS50 od Harvard University](https://www.youtube.com/cs50)
- [Generative AI od Google](https://www.cloudskillsboost.google/paths/118)
- [Chain of Thought](https://every.to/chain-of-thought)
- [Szkolenia od Deeplearning.ai](https://www.deeplearning.ai/courses/)

# Repositories

- (No explicit code repositories or examples were listed in the document.)
