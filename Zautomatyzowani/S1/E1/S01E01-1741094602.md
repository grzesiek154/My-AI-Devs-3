Czytanie, pisanie, słuchanie, mówienie, rysowanie czy nawet rozumowanie — wszystkie te umiejętności całkiem niedawno były poza zasięgiem komputerów. Natomiast dziś mogę napisać wiadomość ... do mojej listy zadań! Jej treść zostanie zrozumiana i wykorzystana do nawiązania połączenia i pobrania danych, które zostaną użyte w odpowiedzi.

![](https://assets-v2.circle.so/o7s9lqlgfwk73o1y19ihoxxg9ioq)

Tak w zasadzie, to nawet nie muszę pisać. Tak samo zadziała nagranie audio z prośbą o sprawdzenie, dodanie czy zakończenie zadań (różnica poniżej jest widoczna przez animację związaną z nagrywaniem wiadomości).

![](https://assets-v2.circle.so/fabpk0km7g5itw8nvfe0x03r9yjv)

W ten sam sposób mogę zadać praktycznie dowolne pytanie, choć akcje ograniczone są do tych, które sam stworzyłem. Do udzielenia odpowiedzi może zostać użyta wiedza ze wskazanych stron czy filmów. Źródłem danych może być także kilkadziesiąt milionów znaków moich publikacji oraz informacje o których zapamiętanie poprosiłem w przeszłości.

> Ważne: **pamięć długoterminowa nie jest domyślnie dostępna w aplikacji Alice**. W dalszych lekcjach zobaczymy w jaki sposób możemy zbudować taką funkcjonalność dla siebie i korzystać z niej nie tylko w Alice.

![](https://assets-v2.circle.so/w0agly3ovzhh911fdd05sgpn3y3a)

Gdy nie mam możliwości swobodnie przeczytać takiej odpowiedzi, mogę ją odsłuchać, [o czym można przekonać się tutaj](https://cloud.overment.com/eoa_endel-1707422536.mp3). Obecne AI dość swobodnie potrafi przeczytać tekst, nawet korzystając przy tym z naszego głosu.

Ze względu na charakter mojej pracy, pracuję także z grafiką, którą także tworzę z pomocą [Midjourney](https://www.midjourney.com/imagine) czy [imagen-3](https://replicate.com/google/imagen-3). Ponownie wszystko sprowadza się tutaj do wysłania wiadomości opisującej to, na czym mi zależy.

![](https://assets-v2.circle.so/j9u77uuf1yktt80nyprz53xwb5eh)

Wygenerowanie takiego obrazu wymaga napisania dość szczegółowego opisu, zawierającego pewne charakterystyczne wyrażenia. Nie tworzyłem go jednak sam, ponieważ z tym także pomogła mi sztuczna inteligencja.

![](https://assets-v2.circle.so/palyv2h06olmxa44j804wtcyhetl)

Zresztą każdy z wymienionych przykładów, to rozbudowane instrukcje i automatyzacje łączące ze sobą różne narzędzia, które stworzyłem samodzielnie. Ich opracowanie również zajmuje czas i nawet niekiedy wymaga wiedzy, której nie posiadam (!). Odkryłem jednak, że z zastosowaniem AI, może pomóc także samo AI.

> Pomimo tego, że w poniższych filmach pojawiają się modele GPT-4-turbo czy GPT-3.5, zasady działania najnowszych modeli takich jak GPT-4o czy o3-mini pozostają takie same.

[1-6 wid.mp4](https://assets.circle.so/1v9t8e08w4tk746kn5nfztojnm13)

Praktycznie wszystkie te możliwości pojawiły się w niezwykle krótkiej perspektywie czasu. Nietypowe jest w tym, że mówimy o technologii, **której działania nie potrafimy w pełni wyjaśnić.** Nawet Ilya Sutskever, czyli człowiek uznawany za \"twórcę ChatGPT\" w jednym z wywiadów wprost powiedział, że [zaskoczeniem jest dla niego fakt, że ta technologia](https://youtu.be/xym5f0XYlSc?t=736) [**w ogóle działa**](https://youtu.be/xym5f0XYlSc?t=736). Mamy więc tutaj wiele pytań, na które obecnie **nikt nie posiada jednoznacznych odpowiedzi**, aczkolwiek są też takie, na które potrafimy odpowiedzieć.

Naturalnie utrudnia to naukę, korzystanie, eksplorowanie i budowanie czegokolwiek z pomocą \"obecnego AI\". Niewiele też wskazuje na to, że cokolwiek się tutaj zmieni. Dlatego **naszym celem nie jest zdobycie umiejętności posługiwania się tym, co jest aktualnie dostępne**. Taka wiedza szybko stanie się nieaktualna. W zamian skupimy się na **zbudowaniu zrozumienia** tego, z czym mamy do czynienia. Pozwoli nam to na skuteczne poruszanie się pośród różnych narzędzi, oraz przede wszystkim — ich praktycznego zastosowania w naszej codzienności.

## Co znajduje się \"po drugiej stronie ChatGPT\"?

Pomimo popularności oraz użyteczności ChatGPT, bardzo zależy mi na tym, abyśmy przy każdej okazji wychodzili poza okno czatu. Otworzy to przed nami zupełnie nowe możliwości związane z możliwością zlecania AI zadań, które będą mogły być wykonane bez naszego aktywnego zaangażowania. Zanim to się stanie, musimy zrozumieć jak to się dzieje, że \"ChatGPT\" jest w stanie odpowiadać na nasze pytania.

![](https://assets-v2.circle.so/8wsq5dv27ztpesnkeoa8x7xgbxxy)

Rozmowa na czacie nie jest czymś nowym w Internecie. Praktycznie każdy z nas korzysta z komunikatorów niemal każdego dnia. Firma OpenAI wykorzystała ten fakt, udostępniając ChatGPT. W ten sposób doskonale znany wszystkim interfejs umożliwił łatwą rozmowę z pewnego rodzaju sztuczną inteligencją w postaci tzw. \"dużego modelu językowego\" (eng. Large Language Model, LLM).

ChatGPT jest zatem jedynie narzędziem do wymiany wiadomości. Natomiast faktyczna rozmowa odbywa się z systemem zdolnym do \"rozumienia\" i generowania treści. Z technicznego punktu widzenia, gdy wymieniamy wiadomości w ChatGPT, w tle zostaje utworzone zapytanie do serwerów OpenAI. Struktura tego zapytania wygląda mniej więcej tak, jak na obrazku poniżej.

![](https://assets-v2.circle.so/1knwkkd79trqtkty0f0ze5wwg6h2)

Pozornie jest to dość skomplikowane. W praktyce, to nic innego jak lista wiadomości składających się na konwersację. Ich treść przekazywana jest do dużego modelu językowego (LLM) **za każdym razem**. Jego zadaniem jest przeanalizowanie jej treści, oraz wygenerowanie możliwie najbardziej sensownej odpowiedzi.

Z punktu widzenia typowego użytkownika ChatGPT, to co dzieje się pod spodem, może być w dużym stopniu zignorowane. W naszym przypadku wygląda to inaczej, ponieważ zależy nam na wyjściu poza okno czatu i sięgnięcia po możliwości LLM w naszych automatyzacjach. Dzięki narzędziom no-code zaprojektujemy scenariusze, zdolne do tworzenia zapytań do modelu, podobnie jak ChatGPT. Jednak w tym przypadku nasza rola w takich interakcjach zostanie ograniczona do niezbędnego minimum. Inaczej mówiąc — część z naszych zadań zostanie wykonana dla nas przez AI, dając nam przestrzeń na pracę, której AI nie może lub nie powinno wykonywać. Zanim to się stanie, wystarczy na teraz zapamiętać, że **możliwe jest nawiązanie bezpośredniego kontaktu z LLM**, bez konieczności otwierania okna czatu.

Tworząc bezpośrednie interakcje z LLM, możemy je swobodnie kształtować i dopasowywać do naszych potrzeb. Do gry wchodzi tutaj nawet łączenie ze sobą automatyzacji, które będą mogły współpracować ze sobą nad wspólnym celem. To wszystko z łatwością może doprowadzić do sytuacji, gdy zaprojektowane przez nas funkcjonalności pozwolą na robienie rzeczy wykraczających poza aktualne możliwości LLM. Zresztą kilka przykładów z własnej codzienności, pokazałem powyżej.

[1-9 wid.mp4](https://assets.circle.so/nf1l3kb31yvnj8vbe58loexxxy9j)

## Czym jest Generatywna Sztuczna Inteligencja?

Kilkukrotnie wspominałem o LLM oraz narzędziach zdolnych do generowania treści, które wspólnie stanowią obszar AI określany jako Generatywna Sztuczna Inteligencja. Zanim będziemy mogli z niej skorzystać w praktyce, warto spojrzeć na ten temat z nieco szerszej perspektywy. W ten sposób wykreujemy wyobrażenie, które będzie pomocne podczas bezpośredniego kontaktu z LLM.

Na co dzień korzystamy z programów komputerowych i aplikacji, które w uproszczeniu można określić jako **zestaw zasad określających przepływ informacji**. Na etapie ich tworzenia, zasady muszą zostać programistycznie opisane w sposób zrozumiały dla komputera, oraz przedstawione wizualnie w sposób wygodny dla człowieka.

Przykładem prostego programu może być galeria zdjęć. Nawet nie posiadając programistycznego doświadczenia, potrafimy wskazać kilka reguł określających sposób wyświetlania i przełączania zdjęć. Stanowi to przykład zasad określających sposób przepływu informacji, które mogą zostać przetłumaczone na kod źródłowy programu.

![](https://assets-v2.circle.so/ubflrk91u9nucl4wc91w1xrbd2bu)

Jeśli w podobny sposób spojrzymy na procesy kreatywne, to szybko zauważymy, że opisanie wszystkich ich zasad jest praktycznie niemożliwe. Nie pomoże nam nawet obszerna wiedza uwzględniająca teorię, reguły czy różne techniki, bo musielibyśmy także opisać sposoby ich zastosowania, które mogłyby zostać przełożone na kod.

Wystarczy spojrzeć na poniższe zdjęcie, które nawet nie jest zdjęciem, lecz wygenerowanym obrazem. Opisanie listy kroków koniecznych do jego stworzenia jest zbyt skomplikowane, aby mogło zostać opisane w kodzie. Tym bardziej, że nasze zadanie nie polegałoby na stworzeniu programu zdolnego do tworzenia tego konkretnego zdjęcia, ale zamieniającego kilka słów opisu na ich wizualną formę w postaci fotorealistycznego obrazu.

![](https://assets-v2.circle.so/vxc6y7qshxczlx2ab1ms93uiqup9)

Złożoność tego problemu jest na tyle duża, że możemy uznać jego rozwiązanie za niemożliwe. Jednak sytuacje w których nie jesteśmy w stanie czegoś szczegółowo opisać, są dość powszechne. Jednym ze sposobów w jaki sobie z nimi radzimy, jest posługiwanie się uproszczeniami, z pomocą których **modelujemy obraz rzeczywistości**.

Stworzenie takiego obrazu zwykle leży w naszym zasięgu. Mając go, możemy wykorzystywać go na różne sposoby, bez konieczności każdorazowego uwzględniania wszystkich detali. Dobrym przykładem może być zwykła mapa, która nie zawiera wszystkich szczegółów opisywanego terenu, ale jest na tyle precyzyjna, że skutecznie pomaga nam w nawigacji.

![](https://assets-v2.circle.so/wrnj2vslw9wp8m00zye56vhu8ia9)

Proces projektowania mapy jest złożony, ale leży w zasięgu człowieka, czego nie można powiedzieć o modelowaniu procesów kreatywnych. Jednocześnie już w przypadku mapy musimy pamiętać o tym, że [nie jest perfekcyjna](https://fs.blog/map-and-territory), o czym wielokrotnie będziemy się przekonywać.

Ostatecznie okazało się, że sam kierunek związany z modelowaniem złożonych procesów okazał się właściwy. Jednak zamiast robić to ręcznie, wykorzystaliśmy dostępną moc obliczeniową komputerów, duże zestawy danych pochodzące z Internetu oraz tzw. sieci neuronowe stworzone na wzór ludzkiego mózgu. Inaczej mówiąc, **stworzyliśmy rozwiązanie zdolne do kształtowania modeli dla procesów, których sami nie jesteśmy w stanie opisać**.

Naturalnie ten materiał nie jest miejscem na wchodzenie w techniczne szczegóły. Wystarczy nam tutaj prosta wizualizacja sieci neuronowej, na której widać pewną strukturę połączeń. Początkowo informacje przepływają przez nią losowo, a sama sieć jest praktycznie bezużyteczna. Zatem jeśli wprowadzimy do niej jakieś dane, to wygenerowana odpowiedź nie będzie mieć większego sensu.

![](https://assets-v2.circle.so/ul2jykgbp2ua1emk1p9mwbxkvce1)

Sieci neuronowe mogą być trenowane, w celu wyspecjalizowania ich w realizacji konkretnych zadań. Celem treningu jest ustawienie sposobu przepływu informacji tak, aby realizować określone zadanie. Cały ten proces wymaga wykonania dużej liczby powtórzeń, które realizujemy dzięki dużej mocy obliczeniowej oraz ogromnej ilości danych.

W przypadku dużych modeli językowych mówimy o sieci składającej się z setek miliardów połączeń, które zostają wyspecjalizowane w zadaniu polegającym na **nieustannym odpowiadaniu na pytanie: \"biorąc pod uwagę dotychczasowy tekst, jaki kolejny fragment jest najbardziej prawdopodobny?\"** Choć trudno w to uwierzyć, dokładnie w ten sposób modele takie jak GPT-4o są w stanie generować treści.

Umiejętność mówienia została tutaj oparta o niezwykle prostą koncepcję \"przewidywania kolejnego fragmentu\" z uwzględnieniem prawdopodobieństwa jego wystąpienia.

![](https://assets-v2.circle.so/gzyxbmitdoxf8pfnx447xclupw1w)

Źródło: [Intro to Large Language Models](https://www.youtube.com/watch?v=zjkBMFhNj_g&t=1890s)

Szczególnie interesujący jest w tym fakt, że wszelkie zasady, schematy, wzorce i uproszczenia związane z rozumieniem oraz generowaniem treści, zostały wykryte i opisane automatycznie. Można więc powiedzieć, że LLM stworzył mapę naszej rzeczywistości, którą posługuje się podczas generowania treści.

Ze względu na złożoność tej \"mapy\", nie jesteśmy w stanie jej zrozumieć. W rezultacie nasza wiedza o działaniu dużych modeli językowych, jest bardzo ograniczona. Znane są nam jedynie zasady, którymi kierowaliśmy się podczas ich tworzenia, oraz możemy obserwować ich zachowania, wśród których znalazły się również takie, których nie planowaliśmy.

Jednym z przykładów jest zdolność modelu (pojawiająca się już od GPT-4) do rozumienia stanu emocjonalnego rozmówcy, o czym możemy przeczytać w publikacji [Theory of Mind Might Have Spontaneously Emerged in Large Language Models](https://arxiv.org/abs/2302.02083). Pokazuje nam to, że nie jesteśmy w stanie jednoznacznie określić umiejętności, które LLMy rozwinęły na etapie treningu. Tworzy to więc przestrzeń do eksploracji i szukania odpowiedzi na pytania o ich praktyczne zastosowanie oraz rolę w naszej codzienności.

## Wnioski z teorii działania dużych modeli językowych

Wątek teoretyczny, przez który właśnie przeszliśmy miał na celu zwrócenie uwagi na pewne cechy obecnego AI, które będziemy obserwować w praktyce. Te najważniejsze z nich, zebrałem w formie następujących podpunktów:

*   ChatGPT jest wyłącznie wizualnym narzędziem umożliwiającym kontakt z dużym modelem językowym (LLM)

*   Możliwa jest bezpośrednia interakcja z LLM przez tzw. API, z którego możemy korzystać poprzez narzędzia no-code. Pozwala to na projektowanie automatyzacji korzystających z tego, co oferuje nam obecne AI

*   Duże modele językowe opierają się o sieci neuronowe, które kształtują swoje zachowania w trakcie treningu, odkrywając zasady przetwarzania danych. Jako ludzie nie potrafimy precyzyjnie opisać ich działania, przez co pełen obraz LLM nie jest dla nas jasny

*   Duże modele językowe kształtują swój własny obraz rzeczywistości na podstawie tekstu, a nie doświadczeń czy obserwacji. Dlatego obraz ten może nie zawsze być precyzyjny lub w ogóle poprawny.

*   LLM generują treść poprzez przewidywanie jej kolejnego fragmentu pasującego do dotychczasowej treści konwersacji. Zatem w przypadku rozmowy z modelem, pod uwagę brane są wszystkie dotychczasowe wiadomości

*   Proces trenowania modelu jest zamknięty w czasie. Oznacza to, że LLM domyślnie **nie posiada nieograniczonej wiedzy, nie uczy się nowych rzeczy i nie posiada dostępu do aktualnych informacji**

*   Istnieje możliwość połączenia modelu z zewnętrznymi źródłami danych, dzięki czemu możemy adresować ograniczenie bazowej wiedzy oraz umiejętności modelu


Duże modele językowe posiadają także szereg dodatkowych ograniczeń, wynikających bezpośrednio z ich natury i leżącej u ich podstaw technologii. Mowa między innymi o tym, że:

*   LLM posiadają limit długości przetwarzanej treści, którego nie można fizycznie przekroczyć. Jest to tzw. \"limit tokenów\" określany także jako \"token window\"

*   LLM posiada ograniczoną zdolność do utrzymywania uwagi. Oznacza to, że nawet jeśli nie przekroczyliśmy dopuszczalnego limitu kontekstu, nadal niektóre fragmenty treści mogą zostać pominięte przez model

*   LLM generuje treści opierając się na prawdopodobieństwie i zasadach, których dokładnie nie znamy. Odpowiedzi modelu mogą zawierać błędy, choć sama ich treść może wyglądać wiarygodnie. Z tego powodu **zawsze należy nadzorować pracę modelu**, a pozyskane informacje podwójnie weryfikować

*   Generowane przez LLM fragmenty treści, to tzw. \"tokeny\". Mogą to być pojedyncze znaki, części słów lub całe słowa. Limit tokenów określony dla modelu obejmuje zarówno treść generowaną przez model, jak i treść przekazaną wraz z naszym zapytaniem

*   W związku z tym, że nie znamy wszystkich zasad, którymi kieruje się LLM przy dobieraniu kolejnych tokenów, nie mamy także pełnej kontroli nad jego zachowaniem. Możemy jednak nim sterować poprzez zastosowanie znanych technik projektowanie instrukcji dla modelu


## Praktyczne możliwości oraz ograniczenia LLM

Na tym etapie kształtuje nam się obraz tego, co leży w zasięgu dużych modeli językowych, a co nie. Przejdziemy więc teraz przez kilka przykładów stworzonych w narzędziu Playground, o którym powiem więcej przy innej okazji. W tej chwili wystarczy porównać je do ChatGPT umożliwiającego ustawienie kilku dodatkowych parametrów oraz swobodne manipulowanie przebiegiem konwersacji.

Pomimo tego, że na rynku istnieje wiele dużych modeli językowych, niemal zawsze będzie nam zależało na korzystaniu z GPT-4o. Mówię o tym dlatego, że jakość generowanych odpowiedzi jest w dużym stopniu uzależniona od modelu z którym będziemy pracować, oraz od sposobu w jaki będziemy to robić.

[03 — Usecases 2.mp4](https://assets.circle.so/nkjikmaxxgyjegnmsyzojw79guvo)

## **Niedeterministyczna natura**

Treści generowane przez modele są niedeterministyczne. Oznacza to, że **dla tego samego zestawu danych wejściowych, nie zawsze otrzymamy ten sam rezultat**. Sprawia to, że odpowiedzi modelu są różnorodne, ale jednocześnie trudne do przewidzenia. Co więcej, nie posiadamy jednoznacznej informacji wyjaśniającej zachowanie modelu w danym momencie i możemy opierać się wyłącznie o swoje spostrzeżenia.

![](https://assets-v2.circle.so/lp6mdzaqmb57pzsjziln0o3pxvov)![](https://assets-v2.circle.so/3bmk672xsbi9aadwx4v8vnltgg30)

Dwa powyższe przykłady pokazują, że pomimo dokładnie tej samej treści mojej wiadomości, odpowiedź modelu zasadniczo się od siebie różni. Akurat w tym przypadku mówimy o zwykłym przywitaniu i różnorodna treść wygląda tu dość naturalnie. Jednak to samo może mieć miejsce w sytuacji, gdy będzie nam zależało na konkretnym rezultacie i wówczas będzie to stanowiło dla nas problem. Co więcej, nie istnieje sposób, aby go rozwiązać, ale mamy do dyspozycji różne opcje, aby zmniejszyć ryzyko jego wystąpienia.

Zatem przypominając — nie jesteśmy w stanie kontrolować zachowania modelu, ale możemy nim sterować. Oznacza to, że pracując z LLM zawsze będziemy poruszać się w obszarze prawdopodobieństwa i zwiększania szansy na otrzymanie oczekiwanego wyniku, a nie pewności tego, że go otrzymamy.

**Ograniczenia bazowej wiedzy**

Wiedza LLM nie jest nieograniczona i nawet w przypadku dość ogólnych pytań, możemy nie uzyskać satysfakcjonującej nas odpowiedzi. Trudno też oczekiwać posiadania jakichkolwiek informacji dotyczących nas samych oraz naszego aktualnego kontekstu.

![](https://assets-v2.circle.so/wn51q0cflnvb2vvvyyfd04t0zzrg)

Brak danych jest jednym z głównych powodów generowania odpowiedzi będących niezgodnych z prawdą. Może to mieć miejsce nawet w przypadku banalnie prostych pytań, takich jak prośba o podanie aktualnej daty. Poniżej widać, że wypowiedź modelu brzmi wiarygodnie, ale niestety nie ma nic wspólnego z prawdą.

![](https://assets-v2.circle.so/3xizkv1zgp0hol8dvocro7xzu09m)

Powyższy problem na pierwszy rzut oka wprost eliminuje zastosowanie LLM do większości zadań. Jednak w znacznym stopniu możemy go zaadresować poprzez stworzenie połączenia z własnymi źródłami wiedzy, czy nawet Internetem, o czym możemy przekonać się korzystając z ChatGPT.

![](https://assets-v2.circle.so/ezyi6anml2q7qhqxhiejx2d8guo1)

Nie jest to jednak rozwiązanie doskonałe i wciąż istnieje ryzyko uzyskania odpowiedzi niezgodnej z prawdą. Ostatecznie jednak mówimy o skuteczności, która jest wystarczająca do projektowania własnych automatyzacji i narzędzi przydatnych w naszej codzienności.

**Wpływ na zachowanie**

Nie możemy bezpośrednio kontrolować zachowania LLM, ale możemy na nie wpływać, stosując różne techniki. Tym najbardziej popularnym przyjrzymy się już niebawem. Natomiast kluczową informacją jest tutaj fakt, że generowanie odpowiedzi odbywa się poprzez **uzupełnienie całej dotychczasowej treści**.

![](https://assets-v2.circle.so/jvrah6edawdl028dtvtqq8obdmht)

W praktyce oznacza to mniej więcej tyle, że na jakość uzyskanej odpowiedzi wpływa cała dotychczasowa konwersacja, uwzględniając zarówno nasze wiadomości, jak i wypowiedzi modelu. Z tego powodu będzie nam zależało na tym, aby przetwarzana treść zawierała dane, które **będą zwiększały prawdopodobieństwo** tego, że LLM wygeneruje odpowiedź zgodną z naszymi oczekiwaniami.

Przykładem może być wskazanie pożądanego formatu odpowiedzi, np. formatu daty. Obecność takiej informacji zwiększa szansę na to, że odpowiedź zostanie udzielona dokładnie w taki sposób, na którym nam zależy. Jak niebawem się przekonamy, będzie miało to **fundamentalne znaczenie** przy projektowaniu automatyzacji której część logiki będzie realizowana przez AI. Wówczas precyzyjne trzymanie się określonych formatów odpowiedzi będzie kluczowe do poprawnego wykonania zadania, bez konieczności angażowania w ten proces człowieka.

![](https://assets-v2.circle.so/yykvwmzh5fo35twj5sh1s0p9tu9m)

**Ograniczona inteligencja**

LLM uczy się naszego świata i rozwija umiejętności poprzez samodzielne odkrywanie różnego rodzaju schematów obecnych w danych treningowych. Proces ten najwyraźniej nie jest doskonały i chociaż modele w wielu sytuacjach radzą sobie świetnie (nierzadko lepiej niż człowiek), tak są sytuacje, gdy ich skuteczność drastycznie spada.

Przykładem może być zdolność do rozumienia relacji opisanymi w tekście. Jak widać poniżej zapisałem wyraźnie, że \"overment\" to Adam, Adam to najlepszy przyjaciel Grzegorza oraz, że najlepszy przyjaciel Grzegorza jest programistą. Pomimo precyzyjnie oddanej relacji, GPT-4 nie jest w stanie powiedzieć, czy wiemy, czym zajmuje się Adam.

![](https://assets-v2.circle.so/ktnhqzlfesqxx5as47fi6xndmtgv)

Nie jest to jednak sytuacja bez wyjścia, ponieważ GPT-4 potrafi poprawnie udzielić odpowiedzi na to pytanie, pod warunkiem, że poprosimy go o wcześniejsze przedstawienie swojego procesu myślowego. W ten sposób dajemy modelowi \"czas na myślenie\", co w tej sytuacji rozumiemy jako dobieranie kolejnych tokenów, z których każdy zwiększa szansę na uzyskanie poprawnej odpowiedzi.

![](https://assets-v2.circle.so/22xepz80ehpe6zo7r07czbz1h055)

Oczywiście takie podejście nie gwarantuje nam powodzenia w każdym przypadku. Po prostu mówimy tutaj o **zwiększaniu szansy** na uniknięcie pomyłki. Przykład ten pokazuje nam zatem, że możliwości rozumowania LLM mają swoje ograniczenia i mogą występować tam, gdzie się tego nie spodziewamy. Jednocześnie widzimy także, że nawet proste poprowadzenie modelu przez konkretne wyrażenia i instrukcje, pozwala znacząco zwiększyć jakość odpowiedzi.

## Skąd czerpać wiedzę na temat dużych modeli językowych?

Patrząc na wszystko, przez co do tej pory przeszliśmy, może nasunąć się pytanie o pochodzenie tych informacji oraz to, czy są rzetelne oraz aktualne. Odpowiedź w tym przypadku jest złożona, ponieważ wiedza ta płynie z połączenia praktyki, teorii udostępnianej przez twórców LLM (np. OpenAI czy DeepMind) oraz doświadczeń innych, nierzadko opisywanych w publikacjach naukowych do których zdarzało mi się linkować. Co więcej, staram się unikać skupiania na gotowych rozwiązaniach, lecz dążyć do źródła wpływającego na zachowanie modelu. W ten sposób cały czas poruszamy się po możliwie fundamentalnej wiedzy, która jest dla nas dostępna, a jednocześnie przekładamy ją na praktyczne zastosowania, o czym jeszcze niejednokrotnie będziemy mieli okazję się przekonać.

Oto najbardziej aktualna lista moich źródeł wiedzy na temat AI:

*   [Prompt Engineering od OpenAI](https://platform.openai.com/docs/guides/prompt-engineering)

*   [Prompting Guide](https://www.promptingguide.ai/)

*   [OpenAI CookBook](https://cookbook.openai.com/)

*   [OpenAI Research](https://openai.com/research)

*   [Anthropic Research](https://www.anthropic.com/research)

*   [OpenAI Community](https://community.openai.com/)

*   [Społeczność AI Explained](https://www.youtube.com/@aiexplained-official/videos)

*   [Andrej Karpathy](https://twitter.com/karpathy) i jego prezentacje

*   [Geoffrey Hinton](https://twitter.com/geoffreyhinton)

*   [Yann Lecun](https://twitter.com/ylecun)

*   [Two Minute Papers](https://www.youtube.com/@TwoMinutePapers)

*   [CS50 od Harvard University](https://www.youtube.com/cs50)

*   [Generative AI od Google](https://www.cloudskillsboost.google/paths/118)

*   [Chain of Thought](https://every.to/chain-of-thought)

*   [Szkolenia od Deeplearning.ai](https://www.deeplearning.ai/courses/)


Patrząc na powyższe źródła nietrudno zauważyć, że w dużej mierze skupiają się one na osobach i firmach bezpośrednio zaangażowanych w rozwój AI oraz najlepszych dostępnych modeli.

Obserwując wyżej wymienione profile i strony www, media społecznościowe podsuwają mi także sugestie powiązanych materiałów, które również zwykle charakteryzuje wysoka jakość. Sam staram się unikać profili specjalizujących się wyłącznie w nowościach czy komentowaniu aktualnych wydarzeń, ponieważ rzadko znajduję wśród nich rozbudowane wyjaśnienia, które pomagają mi zrozumieć AI.

## Praca wspólnie ze Sztuczną Inteligencją

Poprowadzenie prostej rozmowy na ChatGPT nie stanowi szczególnego wyzwania. Sytuacja komplikuje się w chwili, gdy zależy nam na osiągnięciu konkretnego rezultatu. Wówczas okazuje się, że generowane odpowiedzi nie są zgodne z naszymi oczekiwaniami, lub wprost wydaje się, że dochodzimy do granic możliwości obecnych modeli oraz wniosku o ich niskiej przydatności w obszarze zawodowym.

W związku z tym, że LLM generuje treść poprzez przewidywanie jej kolejnego fragmentu, mamy możliwość sterowania tym procesem poprzez przekazywane do modelu instrukcje. Techniki ich tworzenia określa się mianem **Prompt Engineeringu** lub **Prompt Designu**, o których będziemy jeszcze mówić i na temat którego źródła linkowałem powyżej.

Prawdą jest, że odpowiednio napisana instrukcja potrafi znacząco podnieść jakość generowanej przez model odpowiedzi i nierzadko będzie to dla nas bardzo pomocne. Jednak nie zawsze będzie nam zależało na tym, aby AI dokładnie wskazało nam rozwiązanie naszego problemu, a jedynie skierowało naszą uwagę tam, gdzie normalnie byśmy nie popatrzyli.

Przykładowo poniżej mamy wypowiedź Alice na temat błędu w pisanym przeze mnie kodzie. Pomimo tego, że żadna z sugestii nie okazała się poprawna, to przejście przez taki proces myślowy pozwolił mi na szybsze zlokalizowanie problemu i jego samodzielne rozwiązanie.

![](https://assets-v2.circle.so/q129nx59pogmuiv8dwd1rdbmesq1)

Należy jednak pamiętać o tym, że nie wszystkie zadania mogą być efektywnie wykonane przez LLM i trudno szukać sposobów na napisanie instrukcji, które będą w stanie to zmienić. Według [jednej z publikacji Harvard Business School](https://www.hbs.edu/ris/Publication%20Files/24-013_d9b45b68-9e74-42d6-a1c6-c72fb70c7282.pdf), LLM może zwiększać produktywność nawet o 40% dla wybranych zadań. Jeśli jednak spróbujemy pracować z AI w obszarze wykraczającym poza jej aktualne możliwości, to nasza produktywność spadnie.

![](https://assets-v2.circle.so/zvo1p6li5leay28ckl37kdie2fcn)

To wszystko brzmi dość logicznie. Nieoczywiste jest jednak podejmowanie decyzji o tym, w których obszarach AI jest w stanie nam skutecznie pomagać, a w których sami poradzimy sobie lepiej. Należy także pamiętać, ze odpowiedź na to pytanie może zmieniać się w czasie ze względu na szybki rozwój tej technologii.

Sam w pracy z AI kieruję się następującymi zasadami:

*   Nie dążę do pełnego zastąpienia moich obowiązków, a co najwyżej elementów wybranych procesów na potrzeby automatyzacji. Moja uwaga skupia się przede wszystkim na podejmowaniu współpracy z AI w celu optymalizacji moich aktywności poprzez częściowe wsparcie, wspólne rozwiązywanie problemów czy prowadzenie rozmów ułatwiających mi pracę

*   Zawsze staram się poświęcać więcej czasu na opisanie mojego problemu oraz dostarczenie wszelkiego niezbędnego kontekstu i informacji, które mogą być pomocne przy wygenerowaniu odpowiedzi. **Ogólna zasada polega tu na tym, aby długość moich wiadomości była mniej więcej taka sama, jak odpowiedzi generowanych przez AI.** Wynika ona z tego, że każde słowo obecne w treści przetwarzanej przez LLM wpływa na sposób przewidywania kolejnych fragmentów. Dopracowując swoje wiadomości zwiększam swój wpływ na jakość generowanej odpowiedzi, pomagając modelowi dojść do oczekiwanego przeze mnie rozwiązania.

*   Gdy zauważam, że dane leży poza zasięgiem możliwości LLM, w pierwszej kolejności próbuję zmienić swoją strategię i rozpoczynam nową konwersację. Jeśli to nie pomoże, rezygnuję z zastosowania AI w danej sytuacji

*   Zwykle celem mojej pracy z AI jest częściowy rezultat. Wygenerowana treść stanowi albo podstawę tego, co samodzielnie dalej kontynuuję lub odwrotnie — sam zaczynam określone zadanie, a rolą AI jest przetworzenie mojej pracy w zdefiniowany przeze mnie sposób. Ponownie więc mówimy tutaj o uzupełnianiu naszych kompetencji


Z powyższych zasad jasno wynika, że na każdym kroku mówimy o **współpracy z AI** w przypadku której role mogą się zmieniać w zależności od sytuacji. Uzyskuję w ten sposób najlepsze rezultaty, ponieważ możliwości AI rozszerzają moje aktualne kompetencje, a moja wiedza i doświadczenie, adresują ograniczenia AI.

* * *

## Zadanie na dziś

W ramach rozgrzewki, podziel się w komentarzu przykładem tego, jak Generatywna Sztuczna Inteligencja już teraz pomaga Ci w pracy lub **jak wyobrażasz sobie, że mogłaby Ci pomóc**, np. posiłkując się przykładem z Internetu. Dla ułatwienia możesz skorzystać z poniższego szablonu:

*   Opis aktywności:

*   Rola AI:

*   Potencjalne problemy:

*   Największa wartość:


Zwróć szczególną uwagę na wpływ długoterminowy, a nie wyłącznie na aktualne korzyści. Przykładowo generowanie treści na bloga przez AI może stanowić ogromną oszczędność czasu, jednak może mieć to negatywny wpływ na wizerunek i/lub budowanie relacji z odbiorcami.

⚠️ Proszę, nie odkładaj tego zadania na później. To prosta sprawa zajmie Ci nie więcej niż godzinę, a w przyszłości oszczędzisz mnóstwo czasu. I nie zostawiaj nas też bez potwierdzenia, że je wykonałeś/aś — napisz o swoim rozwiązaniu w komentarzu.